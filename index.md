---
mathjax: true
---
# Overview
The project, spanned over a period of slightly over 3 months, consisted in improving the way in SageMath checks for graph isomorphism.  
The plan was first implementing an interface to one of the fastest, if not the fastest, automorphism and isomorphism checking open-source library, Nauty, an interface that could turn useful both as a standalone isomorphism checker and as a benchmarking tool.  
Subsequently, an implementation would be made of the Weisfeiler-Lehman (WL) method: such method, described in [this 1968 paper][1], computes the coherent closure of an arbitrary (di)graph in polynomial time; in simpler terms, the method starts with an initial partition of the vertices (resp. edges) of a graph G and refines this partition through several passes, until the partition resulting by a refinement round is equal to the one the round started with; this resulting, final partition, has the property of being equal to or refined by the orbits (resp. orbitals) of the original graph's automorphism group, and we say WL recognizes a graph if the resulting partition is equal to its orbits (resp. orbitals).  
While this is called the Weisfeiler-Lehman algorithm, it's more correct to say family of algorithms, since for any positive *k* a version of WL can be defined which recognizes strictly more graphs than any other, lower order, WL[^CFI].  

As said above, scope of the project was implementing this family of algorithms, or at least part of it: in particular, the idea was implementing a generic, parametric method that could allow to run any order of Weisfeiler-Lehman if at all possible; since it was not possible to determine if such a thing could be done before enough research was done on how to actually implement WL, a fallback plan was prepared, consisting in manually implementing, separately, the first three orders of WL (the choice of restricting it to the first 3 was made due to the results presented in this paper[^planar]).

Lastly, the project provided for the implementation of an isomorphism checking method which could use k-WL to distinguish graphs in a faster way.

# Trac Tickets

SageMath development process is based around git and an issue tracking system called Trac. Specifically, every improvement, bug/bugfix or new functionality must be reported in a ticket on (https://trac.sagemath.org) with a detailed description, where it will be then discussed, possibly implemented/solved and then reviewed, to then be merged if the process went through successfully.

This means that the work I've done has been divided in tickets on the Trac system, and so will be reported here with a similar structure and organized in chronological order.

To access a particular piece of work described, and thus its in-depth description, discussion and code (which is stored in a separate branch for each ticket), it will suffice to click on the title of its subsection.

In one particular instance, the ticket's original associated branch was changed due to a complete rework of the implementation required, which rendered obsolete the previous code. This means that two subsections of this document will reference the same ticket, but since the branch is still online, the subsection relative to the old implementation will link directly to said branch, skipping the ticket altogether. 

# [\#25391 - Issues in compiling SageMath](https://trac.sagemath.org/ticket/25391)
The subject of the first ticket I've worked on, and also the first difficulty I encountered during my project, was getting SageMath to run at all on my system.  
I started working on a PC running Fedora 28 64bit with gcc 8.1, a fairly updated setup, and this caused a few issues in compiling SageMath's source code.  
In particular, as can be seen in the ticket's description, I had troubles with python3, python2 and linbox packages.  
Now, in all honesty, I could have worked around the issue completely by switching to an older version of the distro, or to another distro altogether, but I thought this could be a good first contribution to SageMath, and the perfect way to gain familiarity with the Trac system and Sage's internal structure and workings before I started working on code that was more relevant to my project.

The actual fixes to the issues I encountered were fairly simple, but debugging the system required a lot of effort, and all the help I could get from my mentor, Dmitrii Pasechnik.  
While at first, after a couple of weeks of work, I was able to produce patches to be included in Sage that could solve the problems listed in the ticket, after some time the upstream maintainers of the packages produced updated versions with fixes included; the ticket, even if fairly successful in providing a solution to the issue, was thus closed because not needed once the packages inside Sage had been updated too.

Still, I consider this ticket very important in my journey, since it really helped me understand how the library I was working on was structured, which parts were where and what to modify and how. In a sense, it served as kind of a workshop before starting work on the real thing.

# [\#25506 - Nauty interface for isomorphism checking and automorphism group computing](https://trac.sagemath.org/ticket/25506)
My second ticket consisted in implementing an interface between Sage and [*nauty*](http://pallini.di.uniroma1.it/)[^nauty], a very fast program for computing automorphism groups and canonical labels (and thus for checking for isomorphisms between graphs).  
The reason why I chose this as my second ticket, instead of implementing k-WL first and then focus on interfaces, is a matter of priorities: I wanted to give something to SageMath's project, and since implementing k-WL in an efficient and useful manner was a challenge, the only sure way of doing so was allowing SageMath's ```automorphism_group``` and ```is_isomorphic``` methods to run faster, using a library that was included in Sage, but never actually incorporated, that is, *nauty*.

My work was heavily based on [*pynauty*](https://web.cs.dal.ca/~peter/software/pynauty/html/), a GPLv3 python module that allows python code to interface with nauty and use it for computing automorphism groups and compare for isomorphism.  
While keeping the same name to give credit, the package I developed for Sage applies a large amount of patches to pynauty's source, basically keeping only the C helper functions used to call on nauty.  
First, I scrapped the Graph building part included in pynauty, since it was not needed for Sage, and modified the python code so that a SageGraph could be passed to it. I then modified the C code to make it parse a SageMath's graph and convert it into a representation useful for nauty, without any wasteful middle conversions. Finally, I made it so that the returned automorphism groups were displayed in a format that was coherent with the one used by the current Sage's ```automorphism_group``` method; of course, the isomorphism checking part didn't need any output adjustments, since it returned a simple boolean.

My work on the interface, anyway, didn't finish here, since nauty's functions, while very fast, in this form were basically useless for Sage, since they required an input (di)graph whose edges were unlabelled and without multiple edges, a very strong restriction for a generic graph library.  
The only way I could find around this issue was described in section 14 of nauty's [documentation](http://pallini.di.uniroma1.it/Guide.html), to which I added a quick fix to allow for multiple edges:

1. If the graph is a multigraph, the multiple edges are removed and their multiplicity is translated to a label: in a number if the original edge had no label, in a pair with the original label as the first member and the multiplicity as the second otherwise; of course, this means that multiple edges on the same extremes should at least have the same labels.
2. If the graph is edge labelled (or if it was a multigraph), convert the labels into *m* consecutive integers starting from 1, where *m* is the number of unique edge labels in the graph; if we're dealing with an isomorphism checking problem, then this step must be done on the disjoint union of the two graphs being checked, that is if two edges in the two graphs have the same label, the edges **must** end up with the same integer label.
3. Finally, each of the *n* vertices is converted into a (strongly) connected component of *log(m)* vertices (for a total of *n log(m)* vertices) and the edges between the new set of nodes is determined by the binary representation of the original edge labels; e.g: if between a vertex a and b there was an edge with label 5, the new graph will have edges (a_0, b_0), (a_2, b_2), since the number 5 has only its first and third bits set.
4. Now, the only thing needed is restricting the action of the computed automorphism group to all of the vertices of the form *v_0*, while respecting the eventual original partition provided to the method; this will give us the automorphism group of the edge labelled (multi)graph.

Finally, I went through Sage's graph automorphism and isomorphism methods, making it so that they could use my interface and adding all the needed glue code, plus modifying the documentation and adding the tests for my algorithm. This was, in my opinion, the most tedious part of the ticket, since it required going through all the existing documentation and adapting it, making sure to keep the same level of quality as the original throughout it.

The main difficulties of this ticket (which consisted in my first real work on the project) were understanding how to correctly modify the source code so that it could interact with Sage, understanding the input and output conventions used by Sage's graph methods, but overall the most difficult part was wrapping my head around more advanced concepts about automorphism groups and isomorphism checking, a feat that required a large amount of studying more than actual programming but that would have proven useful in my quest to implement k-WL.

# [\#25802 - Efficient k-WL implementation (Part 1)](https://git.sagemath.org/sage.git/log/?h=u/Vaush/weisfeiler_lehman_first_implementation)
As anticipated, this subsection is about my first take at a k-WL implementation, thus, while the ticket number refers to a k-WL implementation, it refers to the second one, but the link above takes the user to the first implementation's branch.

This implementation was based off a book draft[^first] describing the nominally best known implementation (in terms of time, probably) of k-WL.  

The algorithm I devised to put that description into code was basically generate and memorise all the tuples in \\(V^n\\) into a hashmap in the form of keys, associating a color with each of them. The starting color of each tuple was determined by the equivalence classes induced by their *ATPs*, that is by the adjacency matrices of the subgraphs induced by the tuples themselves from the original graph G.  
Said adjacency matrices were computed, and all tuples with the same *ATP* were put in the same equivalence class and thus had the same initial coloring; of course, to simplify the code and make execution faster, the colors were represented as integers, so after the division in equivalence classes to each class is assigned an unique integer identifier ranging from 0 to the number of different existing classes minus one.  
After this initialisation phase, the main part of the algorithm can begin: a loop that executes a *refinement round* on the color classes the tuples are divided into, and goes on until the color classes obtained after such *refinement round* are the same as they were before said round started, meaning that they now define a stable coloring for the current order of WL.  
Each refinement round is in theory quite simple and consists in computing a particular ordered multiset of current colorings for each tuple and, again, divide the tuples into new color classes based on the equivalence classes defined by these multisets; since this algorithm had to work with decently large amount of vertices and at least the first few possible values of *k*, special care was needed to ensure that these multisets occupied as little memory as possible and for just the time needed to compute the new color classes, together with ensuring that sorting and dividing in color classes was done in a most efficient way.  
One first way this was achieved was by recognising that, since each round refines a partition, two tuples from different initial color classes could never end up in the same color class at the end of the round: this meant that multisets could be built on a per color class basis, and then deleted soon after computing that specific color class refinement. Another way of improving space efficiency would have been to compact the multisets, by storing a counter of unique values instead of storing repeated values multiple times, but this improvement never saw the light of day because the implementation was scrapped before that.  

To both sort the multisets and divide the tuples in classes based on them, a hybrid sorting algorithm was implemented which used either a bucket counting sort or the standard C++ ```sort``` implementation depending on the size of the set to be sorted and on the range of values therein.  
The choice of using a bucket counting sort was due to the fact that each multiset was really a set of tuples, and that an *ATP* could be considered an array, and thus every sorting needed by the algorithm consisted in sorting sets of fixed, equally long, sets of integers.  
The idea was then to first order the whole set of sets based on each set's first value using counting sort, then divide the outer set into buckets where each bucket's elements had the same first value, and call the sorting procedure on each newly built bucket. At this point, the procedure will decide based on the range of values in the bucket and on its size if C++'s ```sort``` would be better than another counting sort or not, and sort the bucket accordingly on its second value; the same would then be done for the third value, the fourth, and so on, until a bucket ended up having only one item and was thus kept as is, to be later chained with the others to obtain the final sorted set of sets.

This algorithm's time performance was very good given the amount of work it needed to do, but after discussing it with my mentor, it became exceedingly clear that the algorithm could be implmeneted in a different way, that was both faster and less memory hungry. Still, this implementation being very straight-forward and linear, it proved a perfect correctness checking tool for my second implementation later on, before I could develop a more precise way of testing.

There was no major difficulty during this part of the project, but a long series of minor distressful inconvenciences: in no particular order, implementing the particular sorting method described above and getting it to work reliably given its convoluted essence was no easy task, but also understanding how k-WL should work from a summary description in a paper through trial and error proved quite difficult; all in all, this part required a lot of time to bring to completion, but was very useful in understanding enough of k-WL to be able to implement the second version of the algorithm later on.

# [\#25891 - Implementing generators for Hamming graphs, Egawa graphs and Cai-Furer-Immerman graphs](https://trac.sagemath.org/ticket/25891)
While testing my first implementation and discussing it with my mentor, and also during the time we discussed about the new implementation and how it should work, to avoid staying idle I decided to implement a few generators in SageMath for graphs that have interesting properties related to k-WL, which would make them useful for eventual tests or benchmarks.

Specifically, I implemented the following:

* Egawa Graphs[^egawa]
: A family of graphs with parameters \\(p\\) and \\(s\\), named by its author with the letter \\(I\\), whose members are distance regular graphs of diameter \\(2p + s\\) that have the same parameters as the Hamming graph with parameters \\(\(2p + s, 4\)\\), but are not distance transitive if \\(p \neq 0\\).  
This particular family of graphs has the property of not being completely recognised by k-WL for \\(k < 3\\), in particular k-WL cannot produce their orbitals correctly until \\(k = 3\\). Among their properties we can also find that \\(I\(0,s\)\\) is isomorphic to \\(H\(s, 4\)\\) where \\(H\\) is the letter standing for the Hamming graphs, and the fact that no two Egawa graphs with different parameters are isomorphic.  
In general, implementing this generator didn't prove much difficult, since all that had to be done was generating the vertex set through a series of cartesian products and then iterate through the pairs of vertices that had to be connected due to their properties, as described in the paper.

* Hamming Graphs
: This known family of graphs' generator was implemented due to the strong correlation between Egawa graphs and Hamming graphs (they are cospectral mates, and in certain cases, as seen above, even isomorphic). The construction of the two families is also very similar, that of the Hamming graphs being even easier, since it consists in the cartesian product of just one set with itself, instead of the product of two different sets as for the Egawa graphs.  
The most evident properties of Hamming graphs is that they are all distance regular and vertex transitive, that two vertices are connected in the graph if and only if their tuples (generated by the cartesian product mentioned above) have Hamming distance equal to 1 and that the Hamming graph \\(H\(n,q\)\\) is isomorphic to the cartesian product of \\(n\\) complete graphs of order \\(q\\)
* Furer Gadgets
: Furer Gadgets are graphs with a single parameter \\(k\\) and a pretty simple structure, useful only in the construction of the Cai-Furer-Immerman graphs described below. They're made up by a middle layer of \\(2^{k-1}\\) vertices, \\(k\\) upper vertices labelled from \\(a_0\\) to \\(a_{k-1}\\) and \\(k\\) lower vertices labelled from \\(b_0\\) to \\(b_{k-1}\\). Each middle vertex is connected to exactly one of either \\(a_i\\) or \\(b_i, \forall i \in [0,k[\\). A peculiar property, which is what makes them useful for the aformentioned construction, is that a mapping that swaps vertices \\(a_i\\) and \\(b_i\\) is an automorphism if and only if the number of swapped pairs is even.
* Cai-Furer-Immerman Graphs
: Do I have to say it?

---
[1]: https://www.iti.zcu.cz/wl2018/pdf/wl_paper_translation.pdf
[^CFI]: Jin-yi Cai, Martin Fürer, and Neil Immerman. An optimal lower bound on the number of variables for graph identifications. Combinatorica, 12(4):389–410, 1992
[^planar]: S. Kiefer, I. Ponomarenko and P. Schweitzer, "The Weisfeiler-Leman dimension of planar graphs is at most 3," 2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science (LICS), Reykjavik, 2017, pp. 1-12. doi: 10.1109/LICS.2017.8005107
[^nauty]: McKay, B.D. and Piperno, A., Practical Graph Isomorphism, II, Journal of Symbolic Computation, 60 (2014), pp. 94-112, http://dx.doi.org/10.1016/j.jsc.2013.09.003
[^first]: https://www.lii.rwth-aachen.de/images/Mitarbeiter/pub/grohe/cr.pdf
[^egawa]: Yoshimi Egawa, Characterization of H(n, q) by the parameters, Journal of Combinatorial Theory, Series A, Volume 31, Issue 2, 1981, Pages 108-125, ISSN 0097-3165, https://doi.org/10.1016/0097-3165(81)90007-8